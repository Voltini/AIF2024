{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "VAf15cKpOiTd",
   "metadata": {
    "id": "VAf15cKpOiTd"
   },
   "source": [
    "Téléchargement base de données + préprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6819959b",
   "metadata": {
    "id": "6819959b"
   },
   "source": [
    "Pour Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xbozjPNqcj_U",
   "metadata": {
    "id": "xbozjPNqcj_U"
   },
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz > /dev/null 2>&1\n",
    "!tar zxvf imagenette2.tgz > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f7054b",
   "metadata": {
    "id": "09f7054b"
   },
   "source": [
    "Pour MacOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86064f8a",
   "metadata": {
    "id": "86064f8a"
   },
   "outputs": [],
   "source": [
    "# test if file exists\n",
    "import os\n",
    "if not os.path.exists('imagenette2.tgz'):\n",
    "    !curl -O -# https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
    "if not os.path.exists('imagenette2'):\n",
    "    !tar -zxvf imagenette2.tgz > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M5gVifREq6Vj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5gVifREq6Vj",
    "outputId": "f9a26700-93fa-43c7-aa5e-e70db373030d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e64b679-4574-4872-a372-bdcf2e8b5e77",
   "metadata": {
    "id": "6e64b679-4574-4872-a372-bdcf2e8b5e77"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "means, stds = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(means, stds),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(means, stds),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def get_imagenette2_loaders(root_path=\"./imagenette2\", **kwargs):\n",
    "\n",
    "    trainset = torchvision.datasets.ImageFolder(\n",
    "        os.path.join(root_path, \"train\"), transform=train_transform\n",
    "    )\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, **kwargs)\n",
    "    testset = torchvision.datasets.ImageFolder(\n",
    "        os.path.join(root_path, \"val\"), transform=test_transform\n",
    "    )\n",
    "    testloader = torch.utils.data.DataLoader(testset, **kwargs)\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "trainloader, testloader = get_imagenette2_loaders(\n",
    "    batch_size=64, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "labels = [\n",
    "    \"tench\",\n",
    "    \"English springer\",\n",
    "    \"cassette player\",\n",
    "    \"chain saw\",\n",
    "    \"church\",\n",
    "    \"French horn\",\n",
    "    \"garbage truck\",\n",
    "    \"gas pump\",\n",
    "    \"golf ball\",\n",
    "    \"parachute\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b7fa6-d651-4839-bda2-0657f3ff3c54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "c20b7fa6-d651-4839-bda2-0657f3ff3c54",
    "outputId": "e41c3be4-6db2-44ed-c653-602dedd45703"
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-m / s for m, s in zip(means, stds)], std=[1 / s for s in stds]\n",
    ")\n",
    "\n",
    "x, y = next(iter(trainloader))\n",
    "img_grid = make_grid(x[:16])\n",
    "img_grid = inv_normalize(img_grid)\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.imshow(img_grid.permute(1, 2, 0))\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-Rn3DquJO74T",
   "metadata": {
    "id": "-Rn3DquJO74T"
   },
   "source": [
    "Modèle 1 : pr-trained VGG11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "myxoTJF2PEIF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "myxoTJF2PEIF",
    "outputId": "058fe3de-5f2a-4a23-9a2e-882068d458c3"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "model_vgg11 = torchvision.models.vgg11(pretrained=True)\n",
    "for param in model_vgg11.features:\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_vgg11.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=4096, out_features=10, bias=True),\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    model_vgg11 = model_vgg11.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OiqIQWnop6gW",
   "metadata": {
    "id": "OiqIQWnop6gW"
   },
   "source": [
    "Modèle 2 : Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TEOcp3uCsWhu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TEOcp3uCsWhu",
    "outputId": "36ae2d6e-60b9-4da3-cfea-672f4c6c529f"
   },
   "outputs": [],
   "source": [
    "model_resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_resnet18.fc = nn.Linear(model_resnet18.fc.in_features, 10)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model_resnet18 = model_resnet18.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yUZPoYQntXU-",
   "metadata": {
    "id": "yUZPoYQntXU-"
   },
   "source": [
    "Entraînement, test et évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QPFtkuztPtUD",
   "metadata": {
    "id": "QPFtkuztPtUD"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "criterion_classifier = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "\n",
    "def train(model, optimizer, trainloader, epochs=30):\n",
    "    t = tqdm(range(epochs))\n",
    "    for epoch in t:\n",
    "        corrects = 0\n",
    "        total = 0\n",
    "        for x, y in trainloader:\n",
    "            loss = 0\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            y_hat = model(x)\n",
    "\n",
    "            loss += criterion_classifier(y_hat, y)\n",
    "            _, predicted = y_hat.max(1)\n",
    "            corrects += predicted.eq(y).sum().item()\n",
    "            total += y.size(0)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            t.set_description(\n",
    "                f\"epoch: {epoch}; current accuracy: {round(corrects / total * 100, 2)}%  \"\n",
    "            )\n",
    "    return corrects / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K2aupdyiPwU8",
   "metadata": {
    "id": "K2aupdyiPwU8"
   },
   "outputs": [],
   "source": [
    "learning_rate = 5e-3\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_hJpMEUTt41Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_hJpMEUTt41Q",
    "outputId": "87a2fe10-2b98-4aec-af77-b4e7166818e5"
   },
   "outputs": [],
   "source": [
    "# vgg11\n",
    "optimizer = torch.optim.Adam(model_vgg11.classifier.parameters(), lr=learning_rate)\n",
    "train(model_vgg11, optimizer, trainloader, epochs=epochs)\n",
    "\n",
    "# resnet18\n",
    "optimizer = torch.optim.Adam(model_resnet18.fc.parameters(), lr=learning_rate)\n",
    "train(model_resnet18, optimizer, trainloader, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mjuGr0NFPyED",
   "metadata": {
    "id": "mjuGr0NFPyED"
   },
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    test_corrects = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            y_hat = model(x).argmax(1)\n",
    "            test_corrects += y_hat.eq(y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return test_corrects / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X0PMVEpNqAqL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0PMVEpNqAqL",
    "outputId": "ca72f893-2eaf-410b-e7ee-688bcac12a0f"
   },
   "outputs": [],
   "source": [
    "model_vgg11.eval()\n",
    "test_acc = test(model_vgg11, testloader) * 100\n",
    "print(f\"Test accuracy vgg11: {test_acc:.2f} %\")\n",
    "\n",
    "model_resnet18.eval()\n",
    "test_acc = test(model_resnet18, testloader) * 100\n",
    "print(f\"Test accuracy resnet18: {test_acc:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n8LClgDeVp1T",
   "metadata": {
    "id": "n8LClgDeVp1T"
   },
   "source": [
    "Méthode 1 : RISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lqDXwXC2Vn8x",
   "metadata": {
    "id": "lqDXwXC2Vn8x"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "def generate_masks(N, s, p1, image_size):\n",
    "    cell_size = np.ceil(np.array(image_size) / s)\n",
    "    up_size = (s + 1) * cell_size\n",
    "\n",
    "    grid = np.random.rand(N, s, s) < p1\n",
    "    grid = grid.astype(\"float32\")\n",
    "\n",
    "    masks = np.empty((N, *image_size))\n",
    "\n",
    "    for i in range(N):\n",
    "        # Random shifts\n",
    "        x = np.random.randint(0, cell_size[0])\n",
    "        y = np.random.randint(0, cell_size[1])\n",
    "        # Linear interpolation\n",
    "        masks[i, :, :] = resize(\n",
    "            grid[i], up_size, order=1, mode=\"reflect\", anti_aliasing=False\n",
    "        )[x : x + image_size[0], y : y + image_size[1]]\n",
    "\n",
    "    masks = masks.reshape(-1, 1, *image_size)\n",
    "    masks = torch.from_numpy(masks).float()\n",
    "\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H3rN-MLkXLlD",
   "metadata": {
    "id": "H3rN-MLkXLlD"
   },
   "outputs": [],
   "source": [
    "def explain(model, N, p1, img, masks):\n",
    "    img = img.unsqueeze(0).to(\"cpu\")\n",
    "    _, _, H, W = img.size()\n",
    "    print(type(img), type(masks))\n",
    "    stack = torch.mul(masks, img)\n",
    "\n",
    "    p = []\n",
    "\n",
    "    for i in tqdm(range(N)):\n",
    "        with torch.no_grad():\n",
    "            input = stack[i : i + 1]\n",
    "            if torch.cuda.is_available():\n",
    "                input = input.cuda()\n",
    "            output = model(input)\n",
    "            p.append(output.to(\"cpu\"))\n",
    "\n",
    "    p = torch.cat(p)\n",
    "\n",
    "    CL = p.size(1)\n",
    "    sal = torch.matmul(p.data.transpose(0, 1), masks.view(N, H * W))\n",
    "    sal = sal.view((CL, H, W))\n",
    "    sal = sal / N / p1\n",
    "    return sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LlhlvQpJYcji",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "LlhlvQpJYcji",
    "outputId": "169c056b-ff42-469d-eb91-8edc550eb3f5"
   },
   "outputs": [],
   "source": [
    "# Visualisation de la importance map pour la prédiction des modèles sur l'image suivante\n",
    "\n",
    "idx = 0\n",
    "\n",
    "img = inv_normalize(x[idx])\n",
    "np_img = np.transpose(img.cpu().detach().numpy(), (1, 2, 0)) * 255\n",
    "np_img = np_img.astype(np.uint8)\n",
    "plt.imshow(np_img)\n",
    "plt.axis(\"off\")\n",
    "input = x[idx].unsqueeze(0)\n",
    "if torch.cuda.is_available():\n",
    "    input = input.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MokdT2vqyte3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MokdT2vqyte3",
    "outputId": "9b7cc226-2e2f-45be-d04f-021136ab8214"
   },
   "outputs": [],
   "source": [
    "output = model_vgg11(input)\n",
    "_, prediction = torch.topk(output, 1)\n",
    "print(f\"VGG11 prediction: {labels[prediction.item()]} (item number {prediction.item()})\")\n",
    "\n",
    "output = model_resnet18(input)\n",
    "_, prediction = torch.topk(output, 1)\n",
    "print(f\"Resnet18 prediction: {labels[prediction.item()]} (item number {prediction.item()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fh6Lf_5QZ0SW",
   "metadata": {
    "id": "Fh6Lf_5QZ0SW"
   },
   "outputs": [],
   "source": [
    "N = 10000  # Number of masks\n",
    "s = 8  # Size of grid\n",
    "p1 = 0.1  # Probability of inclusion\n",
    "\n",
    "masks = generate_masks(N, s, p1, img.shape[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FSj3_10graIM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSj3_10graIM",
    "outputId": "e8d30c24-8222-4bc0-e710-0ca237b076ad"
   },
   "outputs": [],
   "source": [
    "saliency_maps_vgg11 = explain(model_vgg11, N, p1, img, masks)\n",
    "saliency_maps_resnet18 = explain(model_resnet18, N, p1, img, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uD-QTtF0iwES",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "uD-QTtF0iwES",
    "outputId": "55293664-1677-4fe0-97ee-d02131ade5d9"
   },
   "outputs": [],
   "source": [
    "# vgg11\n",
    "plt.imshow(np_img)\n",
    "\n",
    "plt.imshow(saliency_maps_vgg11[4], cmap=\"turbo\", alpha=0.5)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gi6ouzip0jxV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "gi6ouzip0jxV",
    "outputId": "6752ec34-db05-40a9-ca7d-e1e549fac121"
   },
   "outputs": [],
   "source": [
    "# resnet18\n",
    "plt.imshow(np_img)\n",
    "\n",
    "plt.imshow(saliency_maps_resnet18[5], cmap=\"turbo\", alpha=0.5)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SAgSttaV1KGS",
   "metadata": {
    "id": "SAgSttaV1KGS"
   },
   "source": [
    "Méthode 2 : Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yXwaalPW0p--",
   "metadata": {
    "id": "yXwaalPW0p--"
   },
   "outputs": [],
   "source": [
    "class HookFeatures():\n",
    "    def __init__(self, module):\n",
    "        self.feature_hook = module.register_forward_hook(self.feature_hook_fn)\n",
    "    def feature_hook_fn(self, module, input, output):\n",
    "        self.features = output.clone().detach()\n",
    "        self.gradient_hook = output.register_hook(self.gradient_hook_fn)\n",
    "    def gradient_hook_fn(self, grad):\n",
    "        self.gradients = grad\n",
    "    def close(self):\n",
    "        self.feature_hook.remove()\n",
    "        self.gradient_hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J8vaD9ow1yTo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8vaD9ow1yTo",
    "outputId": "62a675b0-3268-4358-a918-0ffea798e6e6"
   },
   "outputs": [],
   "source": [
    "print(model_vgg11)\n",
    "hook = HookFeatures(model_vgg11.features[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bDcS-o-l1ybn",
   "metadata": {
    "id": "bDcS-o-l1ybn"
   },
   "outputs": [],
   "source": [
    "output = model_vgg11(input)\n",
    "output_idx = output.argmax()\n",
    "output_max = output[0, output_idx]\n",
    "output_max.backward()\n",
    "\n",
    "gradients = hook.gradients\n",
    "activations = hook.features\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3]) # we take the average gradient of every chanels\n",
    "for i in range(activations.shape[1]):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i] # we multiply every chanels of the feature map with their corresponding averaged gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DA49m5wb4y9S",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DA49m5wb4y9S",
    "outputId": "339982c5-d4ac-4999-c7ea-e9772281119f"
   },
   "outputs": [],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QrXttQLx1yeO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "QrXttQLx1yeO",
    "outputId": "484807b4-e35d-4e84-fd98-e55a9026d689"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "heatmap = np.maximum(heatmap.detach().cpu(), 0)\n",
    "heatmap /= torch.max(heatmap)\n",
    "heatmap = cv2.resize(np.float32(heatmap), (img.shape[1], img.shape[2]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_RAINBOW) / 255\n",
    "superposed_img = (heatmap) * 0.4 + np_img\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(np.clip(superposed_img,0,1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OotFU1qu1yg7",
   "metadata": {
    "id": "OotFU1qu1yg7"
   },
   "outputs": [],
   "source": [
    "hook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WOpBSSMl1yjf",
   "metadata": {
    "id": "WOpBSSMl1yjf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZV2or3-O1yma",
   "metadata": {
    "id": "ZV2or3-O1yma"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d4513",
   "metadata": {
    "id": "358d4513"
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "@interact(idx=widgets.IntSlider(min=0, max=len(saliency_maps) - 1, step=1, value=0))\n",
    "def visualize_saliency(idx):\n",
    "    img = inv_normalize(x[idx])\n",
    "    np_img = np.transpose(img.cpu().detach().numpy(), (1, 2, 0)) * 255\n",
    "    np_img = np_img.astype(np.uint8)\n",
    "    plt.imshow(np_img)\n",
    "    # numero de la classe prédite, code a modifier car doit pas marcher\n",
    "    maps_idx = y[idx].item()\n",
    "    plt.imshow(saliency_maps[maps_idx], cmap=\"turbo\", alpha=0.5)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
